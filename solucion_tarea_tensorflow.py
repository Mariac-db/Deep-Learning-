# -*- coding: utf-8 -*-
"""Copia de SOLUCIÓN EJERCICIO 3 - Crear una Red Neuronal Artificial en TensorFlow 2.0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A4tbqCgSuFz78iBErjSYc8lX7aatcL-z

<p align="center">
  <img src="https://storage.googleapis.com/kaggle-datasets-images/2243/3791/9384af51de8baa77f6320901f53bd26b/dataset-cover.png" />
  Imagen cortesía de: https://www.kaggle.com/
</p>

## Paso 1: Instalar las dependencias y configurar el entorno de GPU
"""

!pip install tensorflow-gpu==2.0.0.alpha0

"""## Paso 2: Importar las dependencias necesarias para el proyecto"""

import numpy as np
import datetime
import tensorflow as tf
from tensorflow.keras.datasets import fashion_mnist

tf.__version__

"""## Paso 3: Pre procesado de datos

### Cargar el dataset
"""

#Cargar el dataset Fashion Mnist 
(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()

"""### Normalizar las imágenes

Se divide cada imagen en los conjunto de entrenamiento y  de testing entre el valor máximo de cada uno de los píxeles (255).

De este modo, cada píxel se hallará en el rango [0, 1]. Al normalizar las imágenes, nos aseguramos que nuestro modelo de RNA entrenará más rápidamente.
"""

X_train = X_train / 255.0

X_test = X_test / 255.0

"""### Redimensionar el dataset

Como vamos a utilizar una red neuronal totalmente conectada, vamos a redimensionar los subconjuntos de entrenamiento y testing a formato de vector en lugar de en formato de matriz.
"""

#Como cada imagen tiene 28x28 píxeles, usamos la función reshape en todo el dataset de entrenamiento para convertirlo 
# en vectores de tamaño [-1 (todos los elementos), anchura * altura]
X_train = X_train.reshape(-1, 28*28)

X_train.shape

#Redimensionamos el conjunto de testing del mismo modo
X_test = X_test.reshape(-1, 28*28)

"""## Paso 4: Construir la Red Neuronal Artificial

### Definir el modelo

Simplemente se define un objeto de modelo Sequential.
"""

model = tf.keras.models.Sequential()

"""### Añadir la primera capa totalmente conectada (capa Densa)

Hyper-parametros de la capa:
- número de unidades/neuronas: 128
- función de activación: ReLU
- input_shape: (784, )
"""

model.add(tf.keras.layers.Dense(units=128, activation='relu', input_shape=(784, )))

"""## SOLUCIONES A LOS EJERCICIOS:

*   Añadida una segunda capa oculta
*   Incrementado el número de epochs de 5 a 10

"""

model.add(tf.keras.layers.Dense(units=64, activation='relu'))

"""### Añadir una capa de Dropout 

Dropout es una técnica de Regularization donde aleatoriamente se asignan a ciertas neuronas de la red el valor cero. De este modo, mientras se entrena, estas neuronas no actualizarán sus valores. Al tener cierto porcentaje de neuronas sin actualizar, el proceso de entrenamiento toma más tiempo pero por contra tenemos menos posibilidades de sufrir overfitting.
"""

model.add(tf.keras.layers.Dropout(0.2))

"""### Añadir la segunda capa (capa de salida)

- unidades: número de clases (10 en el caso del Fashion MNIST)
- función de activación: 'softmax' (probabilidades de cada clase)
"""

model.add(tf.keras.layers.Dense(units=10, activation='softmax'))

"""### Compilar el modelo

- Optimizer: Adam
- Loss: Sparse softmax (categorical) crossentropy 
"""

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])

model.summary()

"""### Entrenar el modelo"""

model.fit(X_train, y_train, epochs=10)

"""### Evaluación del modelo y predicción"""

test_loss, test_accuracy = model.evaluate(X_test, y_test)



print("Test accuracy: {}".format(test_accuracy))

"""## Paso 5 : Guardar el modelo

### Guardar la arquitectura (topoligía) de la red neuronal
"""

model_json = model.to_json()
with open("fashion_model.json", "w") as json_file:
    json_file.write(model_json)

"""### Guardar los pesos de la red neuronal"""

model.save_weights("fashion_model.h5")